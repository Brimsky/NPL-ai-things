### UZDEVUMS 1: VÄrdu bieÅ¾uma analÄ«ze ###
from collections import Counter

def analyze_word_frequency(text):
    text = text.lower()
    words = text.replace('.', '').replace(',', '').replace('?', '').replace('!', '').split()
    return Counter(words)

def test_uzd1():
    text = """MÄkoÅ†ainÄ dienÄ kaÄ·is sÄ“dÄ“ja uz palodzes. KaÄ·is domÄja, kÄpÄ“c debesis ir pelÄ“kas. 
    KaÄ·is gribÄ“ja redzÄ“t sauli, bet saule slÄ“pÄs aiz mÄkoÅ†iem."""
    frequencies = analyze_word_frequency(text)
    print("\nUZDEVUMS 1 - VÄrdu bieÅ¾uma analÄ«ze:")
    for word, count in sorted(frequencies.items()):
        print(f"{word}: {count} reizes")

### UZDEVUMS 2: Teksta valodas noteikÅ¡ana ###
from langdetect import detect

def detect_language(text):
    try:
        lang = detect(text)
        language_names = {'lv': 'LatvieÅ¡u', 'en': 'AngÄ¼u', 'ru': 'Krievu'}
        return language_names.get(lang, lang)
    except:
        return "NevarÄ“ja noteikt valodu"

def test_uzd2():
    texts = [
        "Å odien ir saulaina diena.",
        "Today is a sunny day.",
        "Ğ¡ĞµĞ³Ğ¾Ğ´Ğ½Ñ ÑĞ¾Ğ»Ğ½ĞµÑ‡Ğ½Ñ‹Ğ¹ Ğ´ĞµĞ½ÑŒ."
    ]
    print("\nUZDEVUMS 2 - Valodas noteikÅ¡ana:")
    for text in texts:
        language = detect_language(text)
        print(f"Teksts: '{text}'\nValoda: {language}\n")

### UZDEVUMS 3: VÄrdu sakritÄ«bu pÄrbaude ###
def analyze_text_similarity(text1, text2):
    words1 = set(text1.lower().replace('.', '').split())
    words2 = set(text2.lower().replace('.', '').split())
    
    common_words = words1.intersection(words2)
    similarity = len(common_words) / len(words1.union(words2)) * 100
    
    return common_words, similarity

def test_uzd3():
    text1 = "Rudens lapas ir dzeltenas un oranÅ¾as. Lapas klÄj zemi un padara to krÄsainu."
    text2 = "KrÄsainas rudens lapas krÄ«t zemÄ“. Lapas ir oranÅ¾as un dzeltenas."
    
    common_words, similarity = analyze_text_similarity(text1, text2)
    print("\nUZDEVUMS 3 - Tekstu sakritÄ«ba:")
    print(f"KopÄ«gie vÄrdi: {', '.join(common_words)}")
    print(f"SakritÄ«bas lÄ«menis: {similarity:.2f}%")

### UZDEVUMS 4: NoskaÅ†ojuma analÄ«ze ###
def analyze_sentiment(text):
    positive_words = {'lielisks', 'apmierinÄts', 'prieks', 'labs', 'patÄ«k'}
    negative_words = {'vÄ«lies', 'slikts', 'nepatÄ«k', 'neatbilst'}
    
    words = text.lower().split()
    pos_count = sum(1 for word in words if word in positive_words)
    neg_count = sum(1 for word in words if word in negative_words)
    
    if pos_count > neg_count:
        return "pozitÄ«vs"
    elif neg_count > pos_count:
        return "negatÄ«vs"
    return "neitrÄls"

def test_uzd4():
    sentences = [
        "Å is produkts ir lielisks, esmu Ä¼oti apmierinÄts!",
        "Esmu vÄ«lies, produkts neatbilst aprakstam.",
        "NeitrÄls produkts, nekas Ä«paÅ¡s."
    ]
    print("\nUZDEVUMS 4 - NoskaÅ†ojuma analÄ«ze:")
    for sentence in sentences:
        sentiment = analyze_sentiment(sentence)
        print(f"Teikums: '{sentence}'\nNoskaÅ†ojums: {sentiment}\n")

### UZDEVUMS 5: Teksta tÄ«rÄ«Å¡ana ###
import re

def clean_text(text):
    # Remove mentions, URLs, and emojis
    text = re.sub(r'@\w+', '', text)
    text = re.sub(r'http\S+', '', text)
    text = re.sub(r'[^\w\s.,!?]', '', text)
    text = text.lower().strip()
    return text

def test_uzd5():
    text = "@John: Å is ir lielisks produkts!!! Vai ne? ğŸ‘ğŸ‘ğŸ‘ http://example.com"
    cleaned = clean_text(text)
    print("\nUZDEVUMS 5 - Teksta tÄ«rÄ«Å¡ana:")
    print(f"Original: {text}")
    print(f"Cleaned: {cleaned}")

### UZDEVUMS 6: AutomÄtiska rezumÄ“Å¡ana ###
def summarize_text(text):
    sentences = text.split('.')
    important_words = ['galvaspilsÄ“ta', 'slavena', 'robeÅ¾ojas', 'valsts']
    
    # Score sentences based on important words
    scored_sentences = []
    for sentence in sentences:
        score = sum(1 for word in sentence.lower().split() if word in important_words)
        if score > 0:
            scored_sentences.append(sentence.strip())
    
    return '. '.join(scored_sentences) + '.'

def test_uzd6():
    text = """Latvija ir valsts Baltijas reÄ£ionÄ. TÄs galvaspilsÄ“ta ir RÄ«ga, kas ir slavena ar savu vÄ“sturisko centru un skaistajÄm Ä“kÄm. Latvija robeÅ¾ojas ar Lietuvu, Igauniju un Krieviju, kÄ arÄ« tai ir piekÄ¼uve Baltijas jÅ«rai. TÄ ir viena no Eiropas SavienÄ«bas dalÄ«bvalstÄ«m."""
    summary = summarize_text(text)
    print("\nUZDEVUMS 6 - Teksta rezumÄ“Å¡ana:")
    print(f"Kopsavilkums: {summary}")

### UZDEVUMS 7: VÄrdu iegulÅ¡ana ###
from gensim.models import Word2Vec
import numpy as np

def create_word_embeddings(words):
    # Create a simple context for our words
    contexts = [
        ['mÄja', 'liela', 'dzÄ«voklis'],
        ['dzÄ«voklis', 'mazs', 'mÄja'],
        ['jÅ«ra', 'dziÄ¼a', 'Å«dens']
    ]
    
    model = Word2Vec(contexts, min_count=1, vector_size=10)
    
    results = {}
    for word in words:
        if word in model.wv:
            results[word] = model.wv[word]
    return results

def test_uzd7():
    words = ['mÄja', 'dzÄ«voklis', 'jÅ«ra']
    embeddings = create_word_embeddings(words)
    print("\nUZDEVUMS 7 - VÄrdu iegulÅ¡ana:")
    for word, vector in embeddings.items():
        print(f"{word}: {vector[:3]}...")  # Show first 3 dimensions

### UZDEVUMS 8: FrÄÅ¾u atpazÄ«Å¡ana ###
def identify_entities(text):
    # Simple rule-based NER
    organizations = []
    persons = []
    
    words = text.split()
    for i in range(len(words)):
        if words[i][0].isupper():
            if i > 0 and words[i-1] in ['Valsts', 'prezidents']:
                persons.append(' '.join(words[i-1:i+1]))
            elif 'UniversitÄte' in words[i:i+2]:
                organizations.append(' '.join(words[i:i+2]))
    
    return persons, organizations

def test_uzd8():
    text = "Valsts prezidents Egils Levits piedalÄ«jÄs pasÄkumÄ, ko organizÄ“ja Latvijas UniversitÄte."
    persons, organizations = identify_entities(text)
    print("\nUZDEVUMS 8 - FrÄÅ¾u atpazÄ«Å¡ana:")
    print(f"Personas: {persons}")
    print(f"OrganizÄcijas: {organizations}")

### UZDEVUMS 9: Teksta Ä£enerÄ“Å¡ana ###
import random

def generate_story(start_phrase):
    templates = [
        "Tur dzÄ«voja {} {}, kas {}.",
        "Katru dienu {} {}, lÄ«dz {}.",
        "BeigÄs {} un {}."
    ]
    
    subjects = ['princese', 'bruÅ†inieks', 'pÅ«Ä·is', 'burvis']
    actions = ['devÄs ceÄ¼ojumÄ', 'meklÄ“ja dÄrgumus', 'cÄ«nÄ«jÄs ar Ä¼aunumu']
    endings = ['atrada laimi', 'kÄ¼uva par varoni', 'atgriezÄs mÄjÄs']
    
    story = [start_phrase]
    for template in templates:
        sentence = template.format(
            random.choice(subjects),
            random.choice(actions),
            random.choice(endings)
        )
        story.append(sentence)
    
    return ' '.join(story)

def test_uzd9():
    start = "Reiz kÄdÄ tÄlÄ zemÄ“..."
    story = generate_story(start)
    print("\nUZDEVUMS 9 - Teksta Ä£enerÄ“Å¡ana:")
    print(story)

### UZDEVUMS 10: TulkoÅ¡ana ###
def translate_to_english(text):
    translations = {
        'Labdien': 'Hello',
        'kÄ': 'how',
        'jums': 'you',
        'klÄjas': 'are doing',
        'Es': 'I',
        'Å¡odien': 'today',
        'lasÄ«ju': 'read',
        'interesantu': 'interesting',
        'grÄmatu': 'book'
    }
    
    words = text.split()
    translated_words = [translations.get(word, word) for word in words]
    return ' '.join(translated_words)

def test_uzd10():
    texts = [
        "Labdien! KÄ jums klÄjas?",
        "Es Å¡odien lasÄ«ju interesantu grÄmatu."
    ]
    print("\nUZDEVUMS 10 - TulkoÅ¡ana:")
    for text in texts:
        translated = translate_to_english(text)
        print(f"OriÄ£inÄls: {text}")
        print(f"Tulkojums: {translated}\n")

if __name__ == "__main__":
    # Run all tests
    test_uzd1()
    test_uzd2()
    test_uzd3()
    test_uzd4()
    test_uzd5()
    test_uzd6()
    test_uzd7()
    test_uzd8()
    test_uzd9()
    test_uzd10()